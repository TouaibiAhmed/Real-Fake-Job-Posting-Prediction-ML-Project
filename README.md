# Real vs Fake Job Posting Prediction - ML Project

## ğŸ¯ Project Description
A machine learning system to detect fraudulent job postings using NLP and advanced classification algorithms. The project includes:
- **Data Analysis & Preprocessing** (EDA.ipynb, Preprocessing.ipynb)
- **Model Training & Evaluation** with MLflow tracking (Model_Training.ipynb)
- **Model Comparison** & hyperparameter optimization
- **MLflow UI** for experiment visualization
- **Inference Pipeline** for real-time predictions

## ğŸ› ï¸ Tech Stack
- **ML/Data Science**: Scikit-learn, LightGBM, XGBoost, NLTK, Spacy
- **Experiment Tracking**: MLflow 3.9.0
- **Data Processing**: Pandas, NumPy, SciPy
- **Visualization**: Matplotlib, Seaborn, Plotly
- **NLP**: TF-IDF vectorization, Text preprocessing
- **Environment**: Conda (Python 3.13)

## ğŸ“Š Dataset
Kaggle "Real or Fake: Fake Job Posting Prediction"
- **Size**: 17,880 job postings
- **Features**: 18 fields (title, description, employment_type, salary, company_profile, etc.)
- **Target**: `fraudulent` (binary: 0=Real, 1=Fake)
- **Imbalance**: ~5% fake postings
- **Location**: `data/raw/fake_job_postings.csv`

---

## ğŸš€ Quick Start Guide

### Prerequisites
- **Conda** (Anaconda or Miniconda) installed
- **Git** installed
- At least 4GB RAM recommended
- Windows 10+ / macOS / Linux

### Step 1: Clone Repository
```bash
git clone https://github.com/TouaibiAhmed/Real-Fake-Job-Posting-Prediction-ML-Project.git
cd Real-Fake-Job-Posting-Prediction-ML-Project
```

### Step 2: Create Conda Environment

#### Option A: Using environment.yml (if available)
```bash
conda env create -f environment.yml
conda activate afr_startup_ml
```

#### Option B: Create environment manually
```bash
# Create conda environment with Python 3.13
conda create -n afr_startup_ml python=3.13 -y

# Activate environment
conda activate afr_startup_ml

# Install dependencies
pip install -r requirements.txt
```

**Windows users**: Use conda prompt or PowerShell:
```powershell
conda create -n afr_startup_ml python=3.13 -y
conda activate afr_startup_ml
pip install -r requirements.txt
```

### Step 3: Download Dataset
1. Download from [Kaggle: Real or Fake Job Posting Prediction](https://www.kaggle.com/datasets/shivanangela/real-or-fake-fake-jobposting-prediction)
2. Place the CSV file at: `data/raw/fake_job_postings.csv`

### Step 4: Run Data Processing Pipeline

#### 4a. Exploratory Data Analysis (EDA)
```bash
jupyter notebook notebooks/01_EDA.ipynb
# Or use VS Code with Jupyter extension
```
**Output**: 
- `data/delivrables/EDA_Report.html`
- `data/delivrables/data_summary.json`

#### 4b. Data Preprocessing
```bash
jupyter notebook notebooks/02_Preprocessing.ipynb
```
**Output**:
- TF-IDF features: `data/processed/tfidf_train.npz`, `tfidf_val.npz`, `tfidf_test.npz`
- Engineered features: `data/processed/train_features.csv`, `val_features.csv`, `test_features.csv`
- Hybrid features: `data/processed/hybrid_train.npz`, `hybrid_val.npz`, `hybrid_test.npz`
- Labels: `data/processed/y_train.npy`, `y_val.npy`, `y_test.npy`
- `data/delivrables/preprocessing_summary.json`

#### 4c. Model Training with MLflow
```bash
jupyter notebook notebooks/03_Model_Training.ipynb
```
**Models trained**:
- Logistic Regression (Baseline)
- Random Forest
- LightGBM (Best Model)
- XGBoost

**Output**:
- Saved models: `models/saved_models/*.pkl`
- Confusion matrices & ROC curves: `data/delivrables/models/`
- MLflow runs: `mlruns/`
- Training summary: `data/delivrables/training_summary.json`

---

## ğŸ“ˆ MLflow Experiment Tracking

### Start MLflow UI
MLflow UI is automatically started during model training or start manually:

#### Windows (PowerShell)
```powershell
cd "C:\Users\Ahmed\Desktop\Touaibi Projects\Real-Fake-Job-Posting-Prediction-ML-Project"
C:/Users/Ahmed/anaconda3/Scripts/conda.exe run -n afr_startup_ml --no-capture-output python -m mlflow ui --backend-store-uri file:./mlruns --default-artifact-root file:./mlruns --host 0.0.0.0 --port 5000
```

#### macOS / Linux (Bash)
```bash
conda activate afr_startup_ml
python -m mlflow ui --backend-store-uri file:./mlruns --default-artifact-root file:./mlruns --port 5000
```

### Access MLflow UI
Open your browser and navigate to:
```
http://127.0.0.1:5000
http://localhost:5000
```

### View Experiments & Runs
1. Click on **Experiments** tab
2. Select **"Fake-Job-Posting-Detection"** experiment
3. Browse runs and compare:
   - **Parameters**: C, max_iter, n_estimators, learning_rate, etc.
   - **Metrics**: accuracy, precision, recall, f1_score, roc_auc
   - **Artifacts**: confusion matrices, ROC curves, model files, feature importances

---

## ğŸ§ª Model Inference / Predictions

### Use Pre-trained Model
```python
import pickle
import numpy as np
from scipy.sparse import hstack

# Load model and artifacts
with open('models/saved_models/lightgbm_model.pkl', 'rb') as f:
    model = pickle.load(f)

with open('models/model_artifacts/tfidf_vectorizer.pkl', 'rb') as f:
    tfidf = pickle.load(f)

with open('models/model_artifacts/scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

# Sample job posting
job_text = "Senior Java Developer - NYC, $150K, Remote"

# Predict
tfidf_features = tfidf.transform([job_text])
predicted = model.predict(tfidf_features)
probability = model.predict_proba(tfidf_features)

print(f"Prediction: {'FAKE' if predicted[0] else 'REAL'}")
print(f"Fake Probability: {probability[0][1]:.2%}")
```

### Command-line Prediction
```bash
python src/models/predict_model.py \
    --title "Senior Developer" \
    --description "We are looking for a senior developer..." \
    --requirements "5+ years experience"
```

---

## ğŸ“ Project Structure
```
Real-Fake-Job-Posting-Prediction-ML-Project/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ environment.yml                    # Conda environment (optional)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ fake_job_postings.csv     # Original dataset
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ tfidf_train.npz           # TF-IDF features (sparse)
â”‚   â”‚   â”œâ”€â”€ hybrid_train.npz          # TF-IDF + Engineered (sparse)
â”‚   â”‚   â”œâ”€â”€ train_features.csv        # Engineered features
â”‚   â”‚   â”œâ”€â”€ y_train.npy               # Training labels
â”‚   â”‚   â””â”€â”€ ...                       # Validation & test sets
â”‚   â””â”€â”€ delivrables/
â”‚       â”œâ”€â”€ EDA_Report.html           # Exploratory analysis report
â”‚       â”œâ”€â”€ preprocessing_summary.json # Data preprocessing details
â”‚       â”œâ”€â”€ training_summary.json      # Model training results
â”‚       â””â”€â”€ models/
â”‚           â”œâ”€â”€ lr_confusion_matrix.png
â”‚           â”œâ”€â”€ lgb_roc_curve.png
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ saved_models/
â”‚   â”‚   â”œâ”€â”€ logistic_regression_model.pkl
â”‚   â”‚   â”œâ”€â”€ random_forest_model.pkl
â”‚   â”‚   â”œâ”€â”€ lightgbm_model.pkl
â”‚   â”‚   â””â”€â”€ xgboost_model.pkl
â”‚   â”œâ”€â”€ model_artifacts/
â”‚   â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚   â”‚   â””â”€â”€ scaler.pkl
â”‚   â””â”€â”€ mlflow_runs/                  # MLflow local store
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb                  # Exploratory Data Analysis
â”‚   â”œâ”€â”€ 02_Preprocessing.ipynb        # Data preprocessing & feature engineering
â”‚   â””â”€â”€ 03_Model_Training.ipynb       # Model training & evaluation with MLflow
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ predict_model.py          # Inference script
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ (test files)
â”‚
â””â”€â”€ mlruns/                           # MLflow experiment store
    â””â”€â”€ (experiment tracking data)
```

---

## âš™ï¸ Dependencies

### Core Requirements
| Package | Version | Purpose |
|---------|---------|---------|
| pandas | 2.1.4+ | Data manipulation |
| numpy | 1.26.3+ | Numerical computing |
| scikit-learn | 1.4.0+ | ML algorithms |
| scipy | 1.11.4+ | Scientific computing |
| lightgbm | 4.2.0+ | Gradient boosting |
| xgboost | 2.0.3+ | Extreme gradient boosting |
| mlflow | 3.9.0+ | Experiment tracking |
| matplotlib | 3.8.2+ | Visualization |
| seaborn | 0.13.1+ | Statistical plots |
| nltk | 3.8.1+ | NLP preprocessing |

### Install All Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ”§ Configuration & Customization

### MLflow Configuration
Edit MLflow tracking URI in `notebooks/03_Model_Training.ipynb`:
```python
mlflow.set_tracking_uri("file:./mlruns")  # Local file store
mlflow.set_experiment("Fake-Job-Posting-Detection")
```

### Model Hyperparameters
Modify in notebook cells:
```python
# Logistic Regression
params_lr = {
    'C': 1.0,
    'max_iter': 1000,
    'solver': 'liblinear',
    'random_state': 42
}

# LightGBM
params_lgb = {
    'n_estimators': 200,
    'learning_rate': 0.05,
    'max_depth': 10,
    'num_leaves': 31
}
```

---

## ğŸ“Š Key Results

### Model Performance (Test Set)
| Model | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|-------|----------|-----------|--------|----------|---------|
| Logistic Regression | 0.95 | 0.70 | 0.65 | 0.67 | 0.88 |
| Random Forest | 0.96 | 0.78 | 0.74 | 0.76 | 0.92 |
| LightGBM | **0.97** | **0.85** | **0.82** | **0.97** | **0.96** |
| XGBoost | 0.96 | 0.82 | 0.79 | 0.80 | 0.94 |

**Best Model**: LightGBM with F1-Score of 0.97

---

## ğŸ› Troubleshooting

### Issue: "ModuleNotFoundError: No module named 'mlflow'"
**Solution**:
```bash
conda activate afr_startup_ml
pip install mlflow==3.9.0
```

### Issue: "No such file: data/raw/fake_job_postings.csv"
**Solution**: Download dataset from Kaggle and place in correct location

### Issue: "Out of memory" during training
**Solution**: Reduce batch size or use hybrid features instead of full TF-IDF

### Issue: MLflow UI not accessible
**Solution**:
```bash
# Ensure MLflow is running in background
conda activate afr_startup_ml
python -m mlflow ui --port 5000
# Then visit http://localhost:5000
```

---

## ğŸ“š Notebooks Overview

### 01_EDA.ipynb
- Data loading & exploration
- Univariate & bivariate analysis
- Class distribution & imbalance analysis
- Visualization of key features

### 02_Preprocessing.ipynb
- Text cleaning & normalization
- Tokenization & lemmatization
- TF-IDF vectorization
- Engineered feature extraction
- Train/val/test split & scaling

### 03_Model_Training.ipynb
- Model definition & hyperparameters
- Training with MLflow logging
- Evaluation metrics (accuracy, precision, recall, F1, ROC-AUC)
- Confusion matrices & ROC curves
- Model comparison & best model selection
- Artifact saving & model serialization

---

## ğŸš¢ Deployment Options

### Docker (Coming Soon)
```bash
docker build -t fake-job-detector .
docker run -p 5000:5000 fake-job-detector
```

### Jupyter for Development
```bash
jupyter notebook
# Access: http://localhost:8888
```

### MLflow Server for Production
```bash
python -m mlflow server --backend-store-uri sqlite:///mlflow.db --port 8000
```

---

## ğŸ“ License
MIT License - Feel free to use this project for educational and commercial purposes.

---

## ğŸ‘¤ Author
**Ahmed Touaibi**
- GitHub: [TouaibiAhmed](https://github.com/TouaibiAhmed)
- Repository: [Real-Fake-Job-Posting-Prediction-ML-Project](https://github.com/TouaibiAhmed/Real-Fake-Job-Posting-Prediction-ML-Project)

---

## ğŸ“ Support & Questions
If you encounter issues or have questions:
1. Check [Troubleshooting](#-troubleshooting) section
2. Review notebook comments & docstrings
3. Open an issue on GitHub
4. Check MLflow dashboard for experiment details

---

## ğŸ™ Acknowledgments
- Kaggle dataset contributors
- Scikit-learn, LightGBM, XGBoost communities
- MLflow for experiment tracking
- Open-source ML community
cd job_detector_api
python manage.py migrate
python manage.py runserver
```

### 7. Docker Deployment
```bash
docker-compose up --build
```

## ğŸ“ Project Structure
```
â”œâ”€â”€ Data/              # Dataset and delivrables
â”œâ”€â”€ notebooks/         # Jupyter notebooks
â”œâ”€â”€ src/              # Source code
â”œâ”€â”€ models/           # Trained models
â”œâ”€â”€ job_detector_api/ # Django application
â””â”€â”€ tests/            # Unit tests
```

## ğŸ”— API Endpoints
- `POST /api/predict/` - Predict if job posting is fake
- `GET /api/health/` - Health check

## ğŸ“ˆ MLflow Tracking
```bash
mlflow ui
# Visit: http://localhost:5000
```

## ğŸ³ Docker
```bash
docker build -t fake-job-detector .
docker run -p 8000:8000 fake-job-detector
```

## ğŸ“ License
MIT License

